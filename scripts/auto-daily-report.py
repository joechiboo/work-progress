"""
æ¯æ—¥è‡ªå‹•å·¥ä½œç´€éŒ„ç”Ÿæˆå™¨
åœ¨æ¯å¤©æ—©ä¸Š 07:00 åŸ·è¡Œï¼Œè‡ªå‹•æ•´ç†æ˜¨å¤©çš„å·¥ä½œç´€éŒ„
"""
import subprocess
import os
import json
from datetime import datetime, timedelta

GITLAB_PATH = "D:\\Gitlab"
PERSONAL_PATH = "D:\\Personal\\Project"
WORK_PROGRESS_PATH = "D:\\Personal\\Project\\work-progress"
AUTHOR = "UCL\\joechiboo"

def get_git_repos(base_path, max_depth=3):
    """éè¿´å°‹æ‰¾æ‰€æœ‰ Git repositories"""
    repos = []
    for root, dirs, files in os.walk(base_path):
        depth = root.replace(base_path, '').count(os.sep)
        if depth >= max_depth:
            dirs[:] = []
            continue
        if '.git' in dirs:
            repos.append(root)
            dirs[:] = []
    return repos

def get_commits_for_date(repo_path, author, date_str):
    """å–å¾—ç‰¹å®šæ—¥æœŸçš„ commits"""
    try:
        # å…ˆæŠ“å…¨éƒ¨ commitsï¼ŒåŒ…å« author name
        cmd = [
            'git', '-C', repo_path, 'log',
            f'--since={date_str} 00:00',
            f'--until={date_str} 23:59',
            '--format=%an|||%H|||%ai|||%s|||%b',
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')

        commits = []
        for line in result.stdout.strip().split('\n'):
            if not line:
                continue
            parts = line.split('|||')
            if len(parts) >= 4:
                author_name = parts[0].strip()
                # åªä¿ç•™ UCL\joechiboo çš„ commitsï¼Œæ’é™¤ merge commits (ç´€ä¼¯å–¬)
                if author in author_name:
                    commits.append({
                        "hash": parts[1].strip()[:8],
                        "time": parts[2].strip()[11:16],
                        "message": parts[3].strip(),
                        "body": parts[4].strip() if len(parts) > 4 else ""
                    })
        return commits
    except Exception as e:
        return []

def categorize_commit(message):
    """ç°¡æ˜“åˆ†é¡"""
    msg_lower = message.lower()
    if any(word in msg_lower for word in ['feat', 'feature', 'æ–°å¢', 'å¯¦ä½œ']):
        return 'åŠŸèƒ½é–‹ç™¼'
    elif any(word in msg_lower for word in ['fix', 'bug', 'ä¿®æ­£', 'ä¿®å¾©']):
        return 'éŒ¯èª¤ä¿®æ­£'
    elif any(word in msg_lower for word in ['refactor', 'é‡æ§‹', 'å„ªåŒ–']):
        return 'é‡æ§‹'
    elif any(word in msg_lower for word in ['docs', 'æ–‡æª”', 'æ–‡ä»¶']):
        return 'æ–‡æª”'
    else:
        return 'å…¶ä»–'

def generate_daily_report(date_str):
    """ç”Ÿæˆå–®æ—¥å ±å‘Š"""
    gitlab_repos = get_git_repos(GITLAB_PATH)
    personal_repos = get_git_repos(PERSONAL_PATH)

    date_obj = datetime.strptime(date_str, '%Y-%m-%d')

    report = {
        "date": date_str,
        "weekday": ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"][date_obj.weekday()],
        "work_projects": [],
        "side_projects": [],
        "summary": {
            "workCommits": 0,
            "sideCommits": 0,
            "totalCommits": 0
        }
    }

    # æ”¶é›†å·¥ä½œå°ˆæ¡ˆ
    for repo in gitlab_repos:
        proj_name = repo.replace(GITLAB_PATH + "\\", "")
        commits = get_commits_for_date(repo, AUTHOR, date_str)
        if commits:
            report["work_projects"].append({
                "name": proj_name,
                "commits": commits,
                "count": len(commits)
            })
            report["summary"]["workCommits"] += len(commits)

    # æ”¶é›†å€‹äººå°ˆæ¡ˆï¼ˆå« uclcloudï¼‰
    for repo in personal_repos:
        proj_name = repo.replace(PERSONAL_PATH + "\\", "")

        # è·³é work-progress æœ¬èº«
        if 'work-progress' in proj_name.lower():
            continue

        commits = get_commits_for_date(repo, AUTHOR, date_str)
        if commits:
            # uclcloud ç®—å·¥ä½œå°ˆæ¡ˆ
            if 'uclcloud' in proj_name.lower():
                report["work_projects"].append({
                    "name": proj_name,
                    "commits": commits,
                    "count": len(commits)
                })
                report["summary"]["workCommits"] += len(commits)
            else:
                report["side_projects"].append({
                    "name": proj_name,
                    "commits": commits,
                    "count": len(commits)
                })
                report["summary"]["sideCommits"] += len(commits)

    report["summary"]["totalCommits"] = report["summary"]["workCommits"] + report["summary"]["sideCommits"]

    # æ’åº
    report["work_projects"].sort(key=lambda x: x["count"], reverse=True)
    report["side_projects"].sort(key=lambda x: x["count"], reverse=True)

    return report

def generate_markdown(report):
    """ç”Ÿæˆå–®æ—¥ Markdown å ±å‘Š"""
    date = report["date"]
    weekday = report["weekday"]
    work_count = report["summary"]["workCommits"]
    side_count = report["summary"]["sideCommits"]
    total_count = report["summary"]["totalCommits"]

    md = f"# ğŸ“… æ¯æ—¥å·¥ä½œç´€éŒ„ - {date} (é€±{weekday})\n\n"

    if total_count == 0:
        md += "ğŸ–ï¸ **ä¼‘å‡æ—¥æˆ–ç„¡æäº¤ç´€éŒ„**\n\n"
        md += f"ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        return md

    md += f"**çµ±è¨ˆ**: å·¥ä½œ {work_count} + Side {side_count} = ç¸½è¨ˆ {total_count} commits\n\n"
    md += "---\n\n"

    # å·¥ä½œå°ˆæ¡ˆ
    if report["work_projects"]:
        md += "## ğŸ’¼ å·¥ä½œå°ˆæ¡ˆ\n\n"
        for proj in report["work_projects"]:
            md += f"### {proj['name']} ({proj['count']} commits)\n\n"
            for commit in proj["commits"]:
                category = categorize_commit(commit["message"])
                md += f"- **{commit['time']}** [{category}] {commit['message']}\n"
            md += "\n"

    # Side Projects
    if report["side_projects"]:
        md += "## ğŸ¨ Side Projects\n\n"
        for proj in report["side_projects"]:
            md += f"### {proj['name']} ({proj['count']} commits)\n\n"
            for commit in proj["commits"]:
                category = categorize_commit(commit["message"])
                md += f"- **{commit['time']}** [{category}] {commit['message']}\n"
            md += "\n"

    md += "---\n\n"
    md += f"ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"

    return md

def git_commit_and_push(date_str, total_commits):
    """è‡ªå‹• commit ä¸¦ push"""
    try:
        os.chdir(WORK_PROGRESS_PATH)

        # git add
        subprocess.run(['git', 'add', '.'], check=True)

        # git commit
        commit_msg = f"docs: æ¯æ—¥å·¥ä½œç´€éŒ„ {date_str} ({total_commits} commits)\n\nğŸ¤– è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        subprocess.run(['git', 'commit', '-m', commit_msg], check=True)

        # git push
        subprocess.run(['git', 'push'], check=True)

        return True
    except subprocess.CalledProcessError as e:
        print(f"Git operation failed: {e}")
        return False

def main():
    # å–å¾—æ˜¨å¤©çš„æ—¥æœŸ
    yesterday = datetime.now() - timedelta(days=1)
    date_str = yesterday.strftime('%Y-%m-%d')

    print(f"========================================")
    print(f"è‡ªå‹•ç”Ÿæˆæ¯æ—¥å·¥ä½œç´€éŒ„: {date_str}")
    print(f"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"========================================\n")

    # ç”Ÿæˆå ±å‘Š
    report = generate_daily_report(date_str)

    print(f"å·¥ä½œå°ˆæ¡ˆ: {report['summary']['workCommits']} commits")
    print(f"Side Projects: {report['summary']['sideCommits']} commits")
    print(f"ç¸½è¨ˆ: {report['summary']['totalCommits']} commits\n")

    # ç”Ÿæˆ Markdown
    markdown = generate_markdown(report)

    # å„²å­˜æª”æ¡ˆ
    daily_folder = os.path.join(WORK_PROGRESS_PATH, "daily-reports")
    os.makedirs(daily_folder, exist_ok=True)

    # ä¾å¹´æœˆåˆ†é¡
    year_month = yesterday.strftime('%Y-%m')
    monthly_folder = os.path.join(daily_folder, year_month)
    os.makedirs(monthly_folder, exist_ok=True)

    md_file = os.path.join(monthly_folder, f"{date_str}.md")
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(markdown)

    # å„²å­˜ JSON
    json_file = os.path.join(monthly_folder, f"{date_str}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    print(f"Markdown: {md_file}")
    print(f"JSON: {json_file}\n")

    # è‡ªå‹• commit å’Œ push
    if report['summary']['totalCommits'] > 0:
        print("æ­£åœ¨ commit ä¸¦ push åˆ° GitHub...")
        if git_commit_and_push(date_str, report['summary']['totalCommits']):
            print("æˆåŠŸæ¨é€åˆ° GitHub!")
        else:
            print("æ¨é€å¤±æ•—ï¼Œè«‹æ‰‹å‹•è™•ç†")
    else:
        print("ç„¡æäº¤ç´€éŒ„ï¼Œè·³é git push")

    print(f"\nå®Œæˆ!")

def merge_to_public():
    """å½™æ•´æ‰€æœ‰æ¯æ—¥ç´€éŒ„åˆ° public/dataï¼ˆè¼¸å‡ºç¶²é éœ€è¦çš„å½™æ•´æ ¼å¼ï¼‰"""
    import glob

    print("\n" + "=" * 80)
    print("å½™æ•´æ¯æ—¥ç´€éŒ„åˆ° public/data")
    print("=" * 80)

    # è®€å–æ‰€æœ‰æ¯æ—¥ç´€éŒ„
    daily_reports_path = os.path.join(WORK_PROGRESS_PATH, "daily-reports")
    all_reports = []

    for year_month_dir in sorted(glob.glob(os.path.join(daily_reports_path, "*"))):
        if not os.path.isdir(year_month_dir):
            continue

        for json_file in sorted(glob.glob(os.path.join(year_month_dir, "*.json"))):
            with open(json_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
                all_reports.append(report)

    if not all_reports:
        print("æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç´€éŒ„")
        return

    # æŒ‰æ—¥æœŸæ’åº
    all_reports.sort(key=lambda x: x['date'])

    start_date = all_reports[0]['date']
    end_date = all_reports[-1]['date']

    print(f"æ‰¾åˆ° {len(all_reports)} å¤©çš„ç´€éŒ„")
    print(f"æ—¥æœŸç¯„åœ: {start_date} ~ {end_date}")

    # è¨ˆç®—ç¸½å¤©æ•¸å’Œé€±æ•¸
    from datetime import datetime
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    days = (end_dt - start_dt).days + 1
    weeks = round(days / 7, 1)

    # å½™æ•´æˆå°ˆæ¡ˆè¦–è§’çš„æ ¼å¼ï¼ˆç¶²é éœ€è¦çš„æ ¼å¼ï¼‰
    # åªåŒ…å«å·¥ä½œå°ˆæ¡ˆï¼Œæ’é™¤ Side Projects
    projects_map = {}

    for daily in all_reports:
        # åªè™•ç†å·¥ä½œå°ˆæ¡ˆï¼ˆæ’é™¤ Side Projectsï¼‰
        for proj in daily.get('work_projects', []):
            proj_name = proj['name']
            if proj_name not in projects_map:
                projects_map[proj_name] = {
                    'name': proj_name,
                    'totalCommits': 0,
                    'commits': []
                }

            for commit in proj['commits']:
                projects_map[proj_name]['commits'].append({
                    'hash': commit['hash'],
                    'date': daily['date'],
                    'message': commit['message'],
                    'body': commit.get('body', ''),
                    'category': categorize_commit(commit['message']),
                    'tags': []
                })
                projects_map[proj_name]['totalCommits'] += 1

    # è½‰æˆåˆ—è¡¨ä¸¦æ’åº
    projects_list = list(projects_map.values())
    projects_list.sort(key=lambda x: x['totalCommits'], reverse=True)

    # çµ„åˆæœ€çµ‚æ ¼å¼
    total_commits = sum(p['totalCommits'] for p in projects_list)
    output = {
        'period': {
            'start': start_date,
            'end': end_date,
            'days': days,
            'weeks': weeks
        },
        'author': AUTHOR,
        'summary': {
            'totalCommits': total_commits,
            'projectCount': len(projects_list),
            'dailyAverage': round(total_commits / days, 1) if days > 0 else 0
        },
        'projects': projects_list
    }

    # å„²å­˜åˆ° public/data
    public_data_path = os.path.join(WORK_PROGRESS_PATH, "public", "data")

    # å„²å­˜å›ºå®šæª”åï¼ˆä¾›ç¶²é ä½¿ç”¨ï¼‰
    output_file = os.path.join(public_data_path, f"work-log-{start_date}-to-{end_date}.json")
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    print(f"\nå·²å„²å­˜: {output_file}")
    print(f"çµ±è¨ˆ: {total_commits} commits / {len(projects_list)} å°ˆæ¡ˆ / æ—¥å‡ {output['summary']['dailyAverage']}")

    return output_file

if __name__ == "__main__":
    main()

    # å½™æ•´åˆ° public/data ä¾›ç¶²é ä½¿ç”¨
    merge_to_public()
