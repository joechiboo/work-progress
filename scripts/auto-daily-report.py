"""
æ¯æ—¥è‡ªå‹•å·¥ä½œç´€éŒ„ç”Ÿæˆå™¨
åœ¨æ¯å¤©æ—©ä¸Š 07:00 åŸ·è¡Œï¼Œè‡ªå‹•æ•´ç†æ˜¨å¤©çš„å·¥ä½œç´€éŒ„
"""
import subprocess
import os
import json
import sys
import logging
from datetime import datetime, timedelta

# è¨­å®š loggingï¼ˆWindows console éœ€è¦è¨­å®š UTF-8ï¼‰
import io
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

# è‡ªå‹•åµæ¸¬ç’°å¢ƒè·¯å¾‘ï¼ˆå…¬å¸ç”¨ D:\ï¼Œå®¶è£¡ç”¨ C:\ï¼‰
if os.path.exists("D:\\Gitlab"):
    GITLAB_PATH = "D:\\Gitlab"
    PERSONAL_PATH = "D:\\Personal\\Project"
    WORK_PROGRESS_PATH = "D:\\Personal\\Project\\work-progress"
else:
    GITLAB_PATH = "C:\\Gitlab"  # å®¶è£¡å¯èƒ½æ²’æœ‰ Gitlab
    PERSONAL_PATH = "C:\\Personal\\Project"
    WORK_PROGRESS_PATH = "C:\\Personal\\Project\\work-progress\\work-progress-ssh"

AUTHOR = "UCL\\joechiboo"

def get_git_repos(base_path, max_depth=4):
    """éè¿´å°‹æ‰¾æ‰€æœ‰ Git repositories"""
    logging.info(f"æƒæ Git repositories: {base_path} (max_depth={max_depth})")
    repos = []

    if not os.path.exists(base_path):
        logging.error(f"è·¯å¾‘ä¸å­˜åœ¨: {base_path}")
        return repos

    for root, dirs, files in os.walk(base_path):
        depth = root.replace(base_path, '').count(os.sep)
        if depth >= max_depth:
            dirs[:] = []
            continue
        if '.git' in dirs:
            repos.append(root)
            logging.debug(f"æ‰¾åˆ° repo: {root}")
            # ä¸è¦ç«‹å³æ¸…ç©º dirsï¼Œç¹¼çºŒæƒæå­ç›®éŒ„ï¼ˆæ”¯æ´å·¢ç‹€ repoï¼‰

    logging.info(f"æ‰¾åˆ° {len(repos)} å€‹ repositories")
    return repos

def get_commits_for_date(repo_path, author, date_str):
    """å–å¾—ç‰¹å®šæ—¥æœŸçš„ commits"""
    try:
        # å…ˆæŠ“å…¨éƒ¨ commitsï¼ŒåŒ…å« author name (åŒ…å«æ‰€æœ‰åˆ†æ”¯)
        cmd = [
            'git', '-C', repo_path, 'log',
            '--all',
            f'--since={date_str} 00:00',
            f'--until={date_str} 23:59',
            '--format=%an|||%H|||%ai|||%s|||%b',
        ]
        result = subprocess.run(cmd, capture_output=True, text=True, encoding='utf-8')

        if result.returncode != 0:
            logging.warning(f"Git command failed for {repo_path}: {result.stderr}")
            return []

        commits = []
        for line in result.stdout.strip().split('\n'):
            if not line:
                continue
            parts = line.split('|||')
            if len(parts) >= 4:
                author_name = parts[0].strip()
                # åªä¿ç•™ UCL\joechibooã€joechibooã€ç´€ä¼¯å–¬ æˆ– Claude çš„ commits
                if author in author_name or author_name == 'joechiboo' or author_name == 'ç´€ä¼¯å–¬' or author_name == 'Claude':
                    commits.append({
                        "hash": parts[1].strip()[:8],
                        "time": parts[2].strip()[11:16],
                        "message": parts[3].strip(),
                        "body": parts[4].strip() if len(parts) > 4 else ""
                    })

        if commits:
            logging.info(f"  âœ“ {os.path.basename(repo_path)}: {len(commits)} commits")

        return commits
    except Exception as e:
        logging.error(f"Error getting commits from {repo_path}: {str(e)}")
        return []

def categorize_commit(message):
    """ç°¡æ˜“åˆ†é¡"""
    msg_lower = message.lower()
    if any(word in msg_lower for word in ['feat', 'feature', 'æ–°å¢', 'å¯¦ä½œ']):
        return 'åŠŸèƒ½é–‹ç™¼'
    elif any(word in msg_lower for word in ['fix', 'bug', 'ä¿®æ­£', 'ä¿®å¾©']):
        return 'éŒ¯èª¤ä¿®æ­£'
    elif any(word in msg_lower for word in ['refactor', 'é‡æ§‹', 'å„ªåŒ–']):
        return 'é‡æ§‹'
    elif any(word in msg_lower for word in ['docs', 'æ–‡æª”', 'æ–‡ä»¶']):
        return 'æ–‡æª”'
    else:
        return 'å…¶ä»–'

def generate_daily_report(date_str):
    """ç”Ÿæˆå–®æ—¥å ±å‘Š"""
    logging.info(f"é–‹å§‹ç”Ÿæˆ {date_str} çš„å ±å‘Š")

    gitlab_repos = get_git_repos(GITLAB_PATH)
    personal_repos = get_git_repos(PERSONAL_PATH)

    date_obj = datetime.strptime(date_str, '%Y-%m-%d')

    report = {
        "date": date_str,
        "weekday": ["ä¸€", "äºŒ", "ä¸‰", "å››", "äº”", "å…­", "æ—¥"][date_obj.weekday()],
        "work_projects": [],
        "side_projects": [],
        "summary": {
            "workCommits": 0,
            "sideCommits": 0,
            "totalCommits": 0
        }
    }

    # æ”¶é›†å·¥ä½œå°ˆæ¡ˆ
    for repo in gitlab_repos:
        proj_name = repo.replace(GITLAB_PATH + "\\", "")
        commits = get_commits_for_date(repo, AUTHOR, date_str)
        if commits:
            report["work_projects"].append({
                "name": proj_name,
                "commits": commits,
                "count": len(commits)
            })
            report["summary"]["workCommits"] += len(commits)

    # æ”¶é›†å€‹äººå°ˆæ¡ˆï¼ˆå« uclcloudï¼‰
    for repo in personal_repos:
        proj_name = repo.replace(PERSONAL_PATH + "\\", "")


        commits = get_commits_for_date(repo, AUTHOR, date_str)
        if commits:
            # uclcloud ç®—å·¥ä½œå°ˆæ¡ˆ
            if 'uclcloud' in proj_name.lower():
                report["work_projects"].append({
                    "name": proj_name,
                    "commits": commits,
                    "count": len(commits)
                })
                report["summary"]["workCommits"] += len(commits)
            else:
                report["side_projects"].append({
                    "name": proj_name,
                    "commits": commits,
                    "count": len(commits)
                })
                report["summary"]["sideCommits"] += len(commits)

    report["summary"]["totalCommits"] = report["summary"]["workCommits"] + report["summary"]["sideCommits"]

    # æ’åº
    report["work_projects"].sort(key=lambda x: x["count"], reverse=True)
    report["side_projects"].sort(key=lambda x: x["count"], reverse=True)

    return report

def generate_markdown(report):
    """ç”Ÿæˆå–®æ—¥ Markdown å ±å‘Š"""
    date = report["date"]
    weekday = report["weekday"]
    work_count = report["summary"]["workCommits"]
    side_count = report["summary"]["sideCommits"]
    total_count = report["summary"]["totalCommits"]

    md = f"# ğŸ“… æ¯æ—¥å·¥ä½œç´€éŒ„ - {date} (é€±{weekday})\n\n"

    if total_count == 0:
        md += "ğŸ–ï¸ **ä¼‘å‡æ—¥æˆ–ç„¡æäº¤ç´€éŒ„**\n\n"
        md += f"ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"
        return md

    md += f"**çµ±è¨ˆ**: å·¥ä½œ {work_count} + Side {side_count} = ç¸½è¨ˆ {total_count} commits\n\n"
    md += "---\n\n"

    # å·¥ä½œå°ˆæ¡ˆ
    if report["work_projects"]:
        md += "## ğŸ’¼ å·¥ä½œå°ˆæ¡ˆ\n\n"
        for proj in report["work_projects"]:
            md += f"### {proj['name']} ({proj['count']} commits)\n\n"
            for commit in proj["commits"]:
                category = categorize_commit(commit["message"])
                md += f"- **{commit['time']}** [{category}] {commit['message']}\n"
            md += "\n"

    # Side Projects
    if report["side_projects"]:
        md += "## ğŸ¨ Side Projects\n\n"
        for proj in report["side_projects"]:
            md += f"### {proj['name']} ({proj['count']} commits)\n\n"
            for commit in proj["commits"]:
                category = categorize_commit(commit["message"])
                md += f"- **{commit['time']}** [{category}] {commit['message']}\n"
            md += "\n"

    md += "---\n\n"
    md += f"ğŸ“… å ±å‘Šç”Ÿæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n"

    return md

def git_commit_and_push(date_str, total_commits):
    """è‡ªå‹• commit ä¸¦ push"""
    try:
        os.chdir(WORK_PROGRESS_PATH)

        # git add
        result = subprocess.run(['git', 'add', 'daily-reports/', 'public/data/'],
                               capture_output=True, text=True, encoding='utf-8')
        if result.returncode != 0:
            logging.error(f"git add failed: {result.stderr}")
            return False
        logging.info(f"git add æˆåŠŸ")

        # git commit
        commit_msg = f"docs: æ¯æ—¥å·¥ä½œç´€éŒ„ {date_str} ({total_commits} commits)\n\nğŸ¤– è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
        result = subprocess.run(['git', 'commit', '-m', commit_msg],
                               capture_output=True, text=True, encoding='utf-8')
        if result.returncode != 0:
            # å¯èƒ½æ²’æœ‰è®Šæ›´ï¼Œé€™ä¸ç®—éŒ¯èª¤
            if 'nothing to commit' in result.stdout or 'nothing to commit' in result.stderr:
                logging.info("æ²’æœ‰è®Šæ›´éœ€è¦ commit")
            else:
                logging.error(f"git commit failed: {result.stderr}")
                return False
        else:
            logging.info(f"git commit æˆåŠŸ: {commit_msg.split(chr(10))[0]}")

        # git push
        result = subprocess.run(['git', 'push'],
                               capture_output=True, text=True, encoding='utf-8',
                               timeout=30)
        if result.returncode != 0:
            logging.error(f"git push failed: {result.stderr}")
            logging.error(f"stdout: {result.stdout}")
            return False

        logging.info(f"git push æˆåŠŸ: {result.stdout}")
        return True
    except subprocess.TimeoutExpired:
        logging.error("git push timeout (30ç§’)")
        return False
    except subprocess.CalledProcessError as e:
        logging.error(f"Git operation failed: {e}")
        logging.error(f"stderr: {e.stderr if hasattr(e, 'stderr') else 'N/A'}")
        return False
    except Exception as e:
        logging.error(f"Unexpected error: {e}", exc_info=True)
        return False

def main():
    # å…ˆåŒæ­¥æœ€æ–°çš„è®Šæ›´
    logging.info("æ­£åœ¨åŒæ­¥é ç«¯è®Šæ›´...")
    try:
        os.chdir(WORK_PROGRESS_PATH)
        result = subprocess.run(['git', 'pull', 'origin', 'main'],
                               capture_output=True, text=True, encoding='utf-8')
        if result.returncode == 0:
            logging.info(f"Git pull æˆåŠŸ: {result.stdout}")
        else:
            logging.warning(f"Git pull å¤±æ•—ï¼Œç¹¼çºŒåŸ·è¡Œ: {result.stderr}")
    except Exception as e:
        logging.warning(f"Git pull ç™¼ç”ŸéŒ¯èª¤ï¼Œç¹¼çºŒåŸ·è¡Œ: {e}")

    # è§£æåƒæ•¸ï¼šå¦‚æœæœ‰ --today å°±ç”¨ä»Šå¤©ï¼Œå¦å‰‡ç”¨æ˜¨å¤©
    import sys
    use_today = '--today' in sys.argv

    if use_today:
        target_date = datetime.now()
    else:
        target_date = datetime.now() - timedelta(days=1)

    date_str = target_date.strftime('%Y-%m-%d')

    logging.info("=" * 60)
    logging.info(f"è‡ªå‹•ç”Ÿæˆæ¯æ—¥å·¥ä½œç´€éŒ„: {date_str}")
    logging.info(f"åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    logging.info("=" * 60)

    # ç”Ÿæˆå ±å‘Š
    try:
        report = generate_daily_report(date_str)
    except Exception as e:
        logging.error(f"ç”Ÿæˆå ±å‘Šå¤±æ•—: {str(e)}", exc_info=True)
        return

    logging.info(f"å·¥ä½œå°ˆæ¡ˆ: {report['summary']['workCommits']} commits")
    logging.info(f"Side Projects: {report['summary']['sideCommits']} commits")
    logging.info(f"ç¸½è¨ˆ: {report['summary']['totalCommits']} commits")

    # ç”Ÿæˆ Markdown
    markdown = generate_markdown(report)

    # å„²å­˜æª”æ¡ˆ
    daily_folder = os.path.join(WORK_PROGRESS_PATH, "daily-reports")
    os.makedirs(daily_folder, exist_ok=True)

    # ä¾å¹´æœˆåˆ†é¡
    year_month = target_date.strftime('%Y-%m')
    monthly_folder = os.path.join(daily_folder, year_month)
    os.makedirs(monthly_folder, exist_ok=True)

    md_file = os.path.join(monthly_folder, f"{date_str}.md")
    with open(md_file, 'w', encoding='utf-8') as f:
        f.write(markdown)

    # å„²å­˜ JSON
    json_file = os.path.join(monthly_folder, f"{date_str}.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)

    logging.info(f"å·²å„²å­˜ Markdown: {md_file}")
    logging.info(f"å·²å„²å­˜ JSON: {json_file}")

    # è‡ªå‹• commit å’Œ push
    if report['summary']['totalCommits'] > 0:
        logging.info("æ­£åœ¨ commit ä¸¦ push åˆ° GitHub...")
        if git_commit_and_push(date_str, report['summary']['totalCommits']):
            logging.info("âœ“ æˆåŠŸæ¨é€åˆ° GitHub!")
        else:
            logging.error("âœ— æ¨é€å¤±æ•—ï¼Œè«‹æ‰‹å‹•è™•ç†")
    else:
        logging.info("ç„¡æäº¤ç´€éŒ„ï¼Œè·³é git push")

    logging.info("å®Œæˆ!")

def merge_to_public():
    """å½™æ•´æ‰€æœ‰æ¯æ—¥ç´€éŒ„åˆ° public/dataï¼ˆè¼¸å‡ºç¶²é éœ€è¦çš„å½™æ•´æ ¼å¼ï¼‰"""
    import glob

    logging.info("\n" + "=" * 60)
    logging.info("å½™æ•´æ¯æ—¥ç´€éŒ„åˆ° public/data")
    logging.info("=" * 60)

    # è®€å–æ‰€æœ‰æ¯æ—¥ç´€éŒ„
    daily_reports_path = os.path.join(WORK_PROGRESS_PATH, "daily-reports")
    all_reports = []

    for year_month_dir in sorted(glob.glob(os.path.join(daily_reports_path, "*"))):
        if not os.path.isdir(year_month_dir):
            continue

        for json_file in sorted(glob.glob(os.path.join(year_month_dir, "*.json"))):
            with open(json_file, 'r', encoding='utf-8') as f:
                report = json.load(f)
                all_reports.append(report)

    if not all_reports:
        logging.warning("æ²’æœ‰æ‰¾åˆ°ä»»ä½•ç´€éŒ„")
        return

    # æŒ‰æ—¥æœŸæ’åº
    all_reports.sort(key=lambda x: x['date'])

    start_date = all_reports[0]['date']
    end_date = all_reports[-1]['date']

    logging.info(f"æ‰¾åˆ° {len(all_reports)} å¤©çš„ç´€éŒ„")
    logging.info(f"æ—¥æœŸç¯„åœ: {start_date} ~ {end_date}")

    # è¨ˆç®—ç¸½å¤©æ•¸å’Œé€±æ•¸
    from datetime import datetime
    start_dt = datetime.strptime(start_date, '%Y-%m-%d')
    end_dt = datetime.strptime(end_date, '%Y-%m-%d')
    days = (end_dt - start_dt).days + 1
    weeks = round(days / 7, 1)

    # å½™æ•´æˆå°ˆæ¡ˆè¦–è§’çš„æ ¼å¼ï¼ˆç¶²é éœ€è¦çš„æ ¼å¼ï¼‰
    work_projects_map = {}
    side_projects_map = {}

    for daily in all_reports:
        # è™•ç†å·¥ä½œå°ˆæ¡ˆ
        for proj in daily.get('work_projects', []):
            proj_name = proj['name']
            if proj_name not in work_projects_map:
                work_projects_map[proj_name] = {
                    'name': proj_name,
                    'totalCommits': 0,
                    'commits': [],
                    'type': 'work'
                }

            for commit in proj['commits']:
                work_projects_map[proj_name]['commits'].append({
                    'hash': commit['hash'],
                    'date': daily['date'],
                    'message': commit['message'],
                    'body': commit.get('body', ''),
                    'category': categorize_commit(commit['message']),
                    'tags': []
                })
                work_projects_map[proj_name]['totalCommits'] += 1

        # è™•ç† Side Projects
        for proj in daily.get('side_projects', []):
            proj_name = proj['name']
            if proj_name not in side_projects_map:
                side_projects_map[proj_name] = {
                    'name': proj_name,
                    'totalCommits': 0,
                    'commits': [],
                    'type': 'side'
                }

            for commit in proj['commits']:
                side_projects_map[proj_name]['commits'].append({
                    'hash': commit['hash'],
                    'date': daily['date'],
                    'message': commit['message'],
                    'body': commit.get('body', ''),
                    'category': categorize_commit(commit['message']),
                    'tags': []
                })
                side_projects_map[proj_name]['totalCommits'] += 1

    # è½‰æˆåˆ—è¡¨ä¸¦æ’åº
    work_projects_list = list(work_projects_map.values())
    work_projects_list.sort(key=lambda x: x['totalCommits'], reverse=True)

    side_projects_list = list(side_projects_map.values())
    side_projects_list.sort(key=lambda x: x['totalCommits'], reverse=True)

    # åˆä½µæ‰€æœ‰å°ˆæ¡ˆï¼ˆç”¨æ–¼ç¶²é ç¯©é¸ï¼‰
    projects_list = work_projects_list + side_projects_list

    # çµ„åˆæœ€çµ‚æ ¼å¼
    total_commits = sum(p['totalCommits'] for p in projects_list)
    output = {
        'period': {
            'start': start_date,
            'end': end_date,
            'days': days,
            'weeks': weeks
        },
        'author': AUTHOR,
        'summary': {
            'totalCommits': total_commits,
            'projectCount': len(projects_list),
            'dailyAverage': round(total_commits / days, 1) if days > 0 else 0
        },
        'projects': projects_list
    }

    # å„²å­˜åˆ° public/data
    public_data_path = os.path.join(WORK_PROGRESS_PATH, "public", "data")
    os.makedirs(public_data_path, exist_ok=True)

    # å„²å­˜å¸¶æ—¥æœŸçš„æª”æ¡ˆï¼ˆå‚™ä»½ç”¨ï¼‰
    dated_file = os.path.join(public_data_path, f"work-log-{start_date}-to-{end_date}.json")
    with open(dated_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    # å„²å­˜å›ºå®šæª”åï¼ˆä¾›ç¶²é ä½¿ç”¨ï¼‰
    latest_file = os.path.join(public_data_path, "work-log-latest.json")
    with open(latest_file, 'w', encoding='utf-8') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)

    logging.info(f"å·²å„²å­˜:")
    logging.info(f"  - {dated_file} (å‚™ä»½)")
    logging.info(f"  - {latest_file} (ç¶²é ä½¿ç”¨)")
    logging.info(f"çµ±è¨ˆ: {total_commits} commits / {len(projects_list)} å°ˆæ¡ˆ / æ—¥å‡ {output['summary']['dailyAverage']}")

    return latest_file

if __name__ == "__main__":
    main()

    # å½™æ•´åˆ° public/data ä¾›ç¶²é ä½¿ç”¨
    merge_to_public()

    # ç¢ºä¿ merge_to_public çš„è®Šæ›´ä¹Ÿè¢« commit å’Œ push
    logging.info("\næ­£åœ¨ commit ä¸¦ push merge_to_public çš„è®Šæ›´...")
    try:
        os.chdir(WORK_PROGRESS_PATH)

        # æª¢æŸ¥æ˜¯å¦æœ‰è®Šæ›´
        status_result = subprocess.run(['git', 'status', '--porcelain'],
                                      capture_output=True, text=True, encoding='utf-8')

        if status_result.stdout.strip():
            # æœ‰è®Šæ›´æ‰ commit
            result = subprocess.run(['git', 'add', 'public/data/'],
                                   capture_output=True, text=True, encoding='utf-8')
            if result.returncode != 0:
                logging.error(f"git add failed: {result.stderr}")
            else:
                logging.info("git add æˆåŠŸ")

                commit_msg = f"docs: æ›´æ–°å½™æ•´è³‡æ–™ {datetime.now().strftime('%Y-%m-%d')}\n\nğŸ¤– è‡ªå‹•ç”Ÿæˆæ–¼ {datetime.now().strftime('%Y-%m-%d %H:%M')}"
                result = subprocess.run(['git', 'commit', '-m', commit_msg],
                                       capture_output=True, text=True, encoding='utf-8')
                if result.returncode != 0:
                    logging.error(f"git commit failed: {result.stderr}")
                else:
                    logging.info(f"git commit æˆåŠŸ: {commit_msg.split(chr(10))[0]}")

                    result = subprocess.run(['git', 'push'],
                                           capture_output=True, text=True, encoding='utf-8',
                                           timeout=30)
                    if result.returncode != 0:
                        logging.error(f"git push failed: {result.stderr}")
                        logging.error(f"stdout: {result.stdout}")
                    else:
                        logging.info(f"âœ“ æˆåŠŸæ¨é€å½™æ•´è³‡æ–™åˆ° GitHub!")
                        logging.info(f"push output: {result.stdout}")
        else:
            logging.info("ç„¡éœ€æ¨é€ï¼ˆæ²’æœ‰è®Šæ›´ï¼‰")
    except subprocess.TimeoutExpired:
        logging.error("git push timeout (30ç§’)")
    except subprocess.CalledProcessError as e:
        logging.error(f"âœ— æ¨é€å½™æ•´è³‡æ–™å¤±æ•—: {e}")
        logging.error(f"stderr: {e.stderr if hasattr(e, 'stderr') else 'N/A'}")
    except Exception as e:
        logging.error(f"Unexpected error: {e}", exc_info=True)
